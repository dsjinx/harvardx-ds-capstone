---
title: "Movielens edx-PH125.9x"
author: "Jin Xin"
date: "Sep, 2022"
output: pdf_document
bibliography: references.bib
---

an introduction/overview/executive summary section that describes the dataset and summarizes the goal of the project and key steps that were performed

a methods/analysis section that explains the process and techniques used, including data cleaning, data exploration and visualization, insights gained, and your modeling approach

a results section that presents the modeling results and discusses the model performance

a conclusion section that gives a brief summary of the report, its limitations and future work

40 points: The report includes all required sections, is easy to follow with good supporting detail throughout, and is insightful and innovative.
## Executive summary
We are going to create a movie recommendation system in this project. This system will predict the possible rating a movie likely to receive from the specified user. We use the RMSE(root mean square error) to evaluate our algorithm performance, and the final achieved RMSE is \textcolor{blue}{?0.80}. The algorithm is based on the Netflix winning latent factor method [@Koren2009], but a rather vanilla version with an extra step of searching user's genres. 

## Introduction
This project is inspired by the $1 million prize competition hosted by Netflix in 2006. The rule of winning is to achieve a 10% more improvement on RMSE, comparing to Netflix own in house algorithm. But in this project, we just use a fraction of Netflix competition dataset (our 10m version against the original size of 100m [@Töscher09]). Our goal in here is simply to achieve a \textcolor{blue}{RMSE < 0.86490} between our prediction and validation set ratings.

In the following sessions, we will look into the dataset first to have a macro view, then we will explain details of the methods to achieve the final goal. 

## Data exploration
First of all, we use the following code to download and prepare the data we need. The code in below is provided by edx-HarvardX PH125.9x teaching team. To successfully obtain the `edx` and `validation` dataset, we need to follow the instructions inside the code chunk below accordingly, with respect to our own computer setup.  

```{r eval=FALSE}
##########################################################
# Create edx set, validation set (final hold-out test set)
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", 
                            repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", 
                            repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", 
                            repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("https://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", 
                             readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), 
                          "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 3.6 or earlier:
movies <- as.data.frame(movies) %>% 
  mutate(movieId = as.numeric(levels(movieId))[movieId],
                                            title = as.character(title),
                                            genres = as.character(genres))
# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                            title = as.character(title),
                                            genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
# if using R 3.5 or earlier, use `set.seed(1)`
set.seed(1, sample.kind="Rounding") 
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, 
                                  list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
      semi_join(edx, by = "movieId") %>%
      semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

We will use the `edx` data to develop and train our model, then apply the trained model on the `validation` data to predict the rating with respect to the user/movie pairs, and evaluate the prediction against the real ratings by the **RMSE** method. So let's look at the macro structure of the dataset first. 

```{r include = FALSE}
# these libraries are used
library(tidyverse)
library(data.table)
library(caret)
library(Matrix)
library(doParallel)
library(glmnet)
library(RcppArmadillo)
load("~/Work/Rproj/PH125.9x/harvardx-ds-capstone/misc/edx.Rdata")
load("~/Work/Rproj/PH125.9x/harvardx-ds-capstone/misc/val.Rdata")
```

Here is the macro view of `edx` dateset:
```{r echo = FALSE}
options(width = 70)

edx_temp <- head(edx)
knitr::kable(edx_temp)
```

Here is the macro view of `validation` dataset:
```{r echo = FALSE}
options(width = 70)

val_temp <- head(validation)
knitr::kable(val_temp)
```

Comparing the `edx` and `validation` dataset, we can tell the `edx` has the size of 9,000,055 × 6, is just a longer version of `validation` with the size of 999,999 × 6.
```{r echo = FALSE}
df_count <-data.frame(set = c("edx", "validation"),
                      size = c(length(edx$rating),
                               length(validation$rating)))

knitr::kable(df_count)

ggplot(df_count, aes(set, y = log(set_length))) + 
  geom_bar(stat = "identity", aes(y = log(size)), width = 0.4)
```

When we look into the details of 'edx' dataset, we have:
```{r echo = FALSE}
options(width = 70)

names(edx)
```

In these 6 headers, we can classify them into three groups: user info, movie info, and rating (the joint info). 

For user info, we have 'userId', 'timestamp'. This 'timestamp' is showing the information about when the movie is rated by the user, and in the Unix Epoch Time format [@Harper2016]. 

For movie info, we have 'movieId', 'title', and 'genres'. One thing need to pay attention is that, one movie can be categarised as multiple 'genres'. 

let's look at one example to have a more straight understanding. 
```{r}
options(width = 70)

#we convert the timestamp column over the entire 'edx' set first 
sample <- edx[, timestamp := 
                as.Date(as.POSIXct(timestamp, origin="1970-01-01"))][9,]

knitr::kable(sample)
```

We can tell this user by 'userId' = 1 rated the movie "The Lion King" with 'movieId' = 364 for 5 stars, on the date 1996-08-02. The movie "Lion King" was released in 1994, and the movie is categorised under Adventure|Animation|Children|Drama|Musical. 

So our job is to use these user and movie info to predict the 'rating', and the 'rating' is ranged between:
```{r echo = FALSE}
range(edx$rating)
```

We see the range is starting from 0.5, but implicitly the floor of the rating range is **0**. Why does this implicit **0** rating assumption may stand? Let us look at number of user/movie paired ratings we have in 'edx':
```{r echo = FALSE}
df_sparse <- data.table(x = c("user_num", "movie_num", "rating_num"),
          y = c(uniqueN(edx$userId), 
                uniqueN(edx$movieId), 
                uniqueN(edx$rating)))

ggplot(df_sparse, aes(x, y = log(x_num))) + 
  geom_bar(stat = "identity", aes(y = log(y)), width = 0.4)
```

Theoretically, there should be: 
```{r}
uniqueN(edx$userId) * uniqueN(edx$movieId)
```

above number of total ratings, but instead we only got 9,000,055 in our dataset. Of course, this is very reasonable, since it is not possible for everyone watched all the movies, and it is also possible for one has watched the movie, but did not rate it. In other word, we can view this as a big matrix with the dimension of user_num: 69878 * movie_num: 10677, however this matrix is highly sparse with only rating_num: 9,000,055 non zero elements, and the reset are all zero. Mathematically, we call this kind of matrix a \textcolor{blue}{"sparse matrix"}. 

From the code at very beginning helped us get the 'edx' and 'validation' datasets, we can tell the 'validation' data is intentionally built based on users and movies of 'edx', which we will use for our algorithm development.
```{r eval = FALSE}
# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
      semi_join(edx, by = "movieId") %>%
      semi_join(edx, by = "userId")
```

That 'userId' and 'movieId' matching process makes the rating matrix of 'validation' be exactly the same as 'edx', so we can further specify our job to be predicting the 'rating' at the corresponding 'userId'-'movieId' position in the big \textcolor{blue}{sparse matrix}, based on the known elements are given by 'edx' dataset. Then it becomes to estimate an element value inside a sparse matrix problem.

After we identified our problem mathematically, one of the most popular algorithm to solve this problem is \textcolor{blue}{Latent Factor method} by @Koren2009. so we will imitate this $1 million algorithm, but in a rather simple way with an extra step of searching user's genres info, which is not included in the dataset. 

## Methods details
Before we get into the details of our algorithm, we will build some heuristic understanding on it first. 

###Foundations
The central idea of our algorithm, as well as the one by @Koren2009, is matrix factorisation. More specifically, it is the idea of PCA or SVD in linear algebra, but on the opposite way. As described by @Bell2007, PCA is the idea of rank minimisation for a dense matrix with no missing entry, but our user-movie rating matrix is highly sparse with most entries are missing, so we are going the opposite way of rank reduction, we are estimating the rank up from zero. To justify our approach, let's break it into two parts: 1, rating matrix factorisation; 2, factor searching. 

Because PCA is just a slim version of SVD, let's build some foundation on SVD first. @Strang2016 tells us any matrix can be factorised by SVD, even the rank 1 matrix: 
$$
A = U\Sigma V^{T}
$$
In the above SVD formula, assume A is a m(rows) by n(cols) matrix, where U is a m(rows) by m(cols) square matrix composed by singular vectors in A's column space $R^{m}$, which captures the feature information of the rows. The V is a n(rows) by n(cols) square matrix composed by singular vectors in A's row space $R^{n}$, which captures the feature information of the columns. Lastly, the $\Sigma$ is a m(rows) by n(cols) diagonal matrix contains f number of singular values of A with the reset min(m,n) - f are all 0's, where f $\leq$ min(m, n). Here is an example of m = 5, f = 3, n = 4 to demonstrate the $\Sigma$:
$$\Sigma = \begin{bmatrix}\sigma_1 & 0 & 0 & 0\\
0 & \sigma_2 & 0 & 0\\
0 & 0 & \sigma_3 & 0\\
0 & 0 & 0 & 0\\
0 & 0 & 0 & 0\\
\end{bmatrix}$$
This number f is critical to us, since it defines how many critical factors is contained in A. We also mentioned before the PCA, the slim version SVD, can help us reduce rank of A without loosing critical information according to the Eckart-Young theorem [@Strang2019]. So we can use this f, or k $\leq$ f more specifically, to shrink the U and V into m by k, and n by k matrix respectively, and this will still enable us to recover a good estimation of A with a smaller U, V through the matrix multiplication. Here we only abstract the key information of SVD and PCA to help us build the foundation of our algorithm, for further details on the topic, this book @Strang2016 will give a comprehensive explanation. 

Now let's apply the standard SVD formula into our scenario, and rewrite it as:
$$
R = PIQ^{T}
$$
Then R is a user_num(rows) by movie_num(cols) rating matrix, P is a user_num(rows) by f(cols) matrix, I is an f(rows) by f(cols) identity matrix, Q is a movie_num(rows) by f(cols) matrix. And what the f is the key to derive our latent factor algorithm. We are assuming there are f fixed number of hidden factors pertained to each user and each movie, according to the matrix multiplication in above, for each element in R can be arrived by:
$$
r_{ui} = \vec{p_u}^{T}\cdot1\cdot\vec{q_i}
$$
The 1 in between $\vec{p_u}^{T}$ and $\vec{q_i}$ can be neglected. we also need to clarify that the $\vec{p_u}^{T}$ is the u-th row of P matrix in above, and same for $\vec{q_i}$ is the i-th column of Q matrix. We are putting the transpose sign on $\vec{p}$ by removing it from $\vec{q}$, is making the equation of $r_{ui}$ to be more linear algebra naturally to the readers. And the length of each $\vec{p_u}$ and $\vec{q_i}$ are the same to be _f_. So with the above understanding, we can remake the R matrix to be more convenient to serve our purpose:
$$
R_{lfm} = P^{T}\cdot Q
$$
Where P is a factor_num by user_num matrix, and Q is a factor_num by movie_num matrix, so $R_{lfm}$ is a user_num by movie_num matrix, and for notation convenient, we will use R to indicate $R_{lfm}$ in reset of the report.

By inspecting the R matrix equation, to be successfully making the estimation on any R element $r_{ui}$, we need the corresponding $\vec{p_u}$ and $\vec{q_i}$. So how can we get this latent factor vector for each user and movie? @Bell2007 solved it by the idea of minimising the loss function ${\frac{1}{2}\|P^{T}\cdot Q - R\|_F^2}$ with the alternating gradient descent, and the alternating iterations here beautifully solved the problem of both P and Q are unknown to us at beginning, the iteration will be like this:
$$\begin{equation*}
P_{t+1} = P_t - \underbrace{Q_t\cdot(P_t^{T}Q_t - R)^{T}}_{\nabla P_t}\\
Q_{t+1} = Q_t - \underbrace{P_t\cdot(P_tQ_t - R)}_{\nabla Q_t}
\end{equation*}$$
The above alternations are not efficient with our sparse matrix scenario though, we just use them as a demonstration, and we will tweak them to fit our purpose later, when we get into the details of our calculation. For more details on gradient descent and why it works, this book @Strang2019 covers all the essentials. Only to have a heuristic understanding about gradient descent, geometrically we are having a convex loss function, because ${\frac{1}{2}\|P^{T}\cdot Q - R\|_F^2}$ $\geq$ 0 is positive semidefinite, ideally a rather simple case is loss this function > 0 a positive definite matrix, then it is a bowl opening up, the bottom point of the bowl is the minimum of the loss function we are working hardly to achieve. On the other hand, by achieving this bottom point, we also minimise our target RMSE function:
$$
RMSE_{matrix} = \|P^{T}Q - R\|_F
$$
up to now, we have built enough understanding to proceed with our algorithm, but we still miss one important part, the number of latent factors to construct each user vector and movie vector, we will leave it at the end within the last step of the computation. With the above foundation, we are ready to get into the computations now. 

###Centralisation
Instead applying our latent factor algorithm directly, we need to centralise user-movie rating matrix first. Traditionally, we only centeralise the measurements vectors in SVD. In our rating matrix, there are tow kinds of measurements, users and movies. If we treat each user as a measurement, then each movie is a sample point, conversely, we treat each movie as a measurement, then each user is a sample point. 
$$
R = \begin{bmatrix} \vec{User_1}^{T}\\
\vec{User_2}^{T}\\
\vdots\\
\vec{User_u}^{T}
\end{bmatrix} = \begin{bmatrix}r_{11} & \ldots & r_{1i} \\
\vdots & \ddots & \vdots\\
r_{u1} & \ldots & r_{ui}
\end{bmatrix} = \begin{bmatrix} \vec{Movie_1} & \vec{Movie_2} & \ldots & \vec{Movie_i}\end{bmatrix}
$$
So in our rating matrix, we have to centralise in both row and column directions simultaneously. To stress the simultaneous centralisation, we are not performing the de-mean on one direction then the other, instead we treat the rating $r_{ui}$ to be in its own r-th dimension, because $r_{ui}$ is the result of some function $f(\vec{user_u}, \vec{movie_i})$. One more thing to consider is the sparsity of our rating matrix, there are very few $r_{ui}$ are known to us, and we don't know whether the user watched the movie, or she just could not be bothered to rate it. So instead impute the missing value places of the matrix with 0's, we just exclude them from our computation. The other reason of doing so is, we will get a 0 mean, because those 0's adding no value to the sum of all ratings, but making our divisor enormously large. 
```{r eval = FALSE}
#global mean
g_mean <- mean(edx$rating)
```
The global mean we just got is the centre of all the available ratings, so it is neither the mean of any user nor mean of any movie. But we can assume this global mean is the centre of all the means of every user, as well as cenre of all the means of each movie, so we can estimate each user's real mean by $User_u\_mean = g\_mean + u\_bias$. 

How can we find the best u_bias for each user? We aim to minimise the $RMSE$:
$$RMSE = \sqrt{\frac{\sum_{ui \in N}(\hat{r_{ui}} - r_{ui})^2}{N}}$$ 
For the sake of simplicity, we will only work on the inner part (squared error), and construct our loss function:
$$
Loss = \frac{1}{2N} \sum_{ui \in N}(\hat{r_{ui}} - r_{ui})^2
$$
we are aiming for the best u_bias so that RMSE can be minimised with the set up of $\hat{r_{ui}} = g\_mean + u\_bias$. 

And what's more, there are active users who rates every movie she watched, and lazy users who rarely rate, so we introduce the regularisation factor ${\lambda}$ to avoid the overfitting risk, so the new regularised loss function becomes to be:
$$
Loss = \frac{1}{2} \sum_{i \in N}(\hat{r_{ui}} - r_{ui})^2 + \frac{\lambda}{2N} \sum_{i \in N}b_u^2
$$
We dropped the $u$ from $ui$ in the $\Sigma$ sign, because we are estimating each user's bias individually based on all the movies rated by her. We also dropped the $N$ from the first part of $\frac{1}{2N}$ to make our computation formula of $b_u$ to be consistent with the Professor Irizarry's text book [@irizarry_2022], some one may prefer to keep it, that is just personal choice, it will only alter the $\lambda$ result, the final $b_u$ should not vary much.

The derived formula to perform the following $b_u$ calculation is:
$$
b_u = \frac{\sum_{i \in N}{(r_i - \bar{r})}}{\lambda + N}
$$

We also employ a 5-fold cross validation method to overcome potential overfitting.
```{r eval = FALSE}

#making 5-folds cross validation sets

set.seed(2, sample.kind= "Rounding")

ind_cv <- createFolds(edx$userId, k = 5)

#utilize the multicores on our computer to parallel the loop
#I am using total cores -1 to avoid system frozen
#number of cores only need to be registered only once globally

registerDoParallel(cores = 3)

train_cv <- foreach(k = 1:5) %dopar% {edx[-ind_cv[[k]],]}

test_cv <- foreach(k = 1:5, .packages = "tidyverse") %dopar% {
    edx[ind_cv[[k]],] %>% 
    semi_join(train_cv[[k]], by = "movieId") %>% 
    semi_join(train_cv[[k]], by = "userId")}

#We did not put back the dropped out data back to train_cv, 
#because they are eventually showing up in other folds. 
#This is just personal choice, we can put them back, 
#but it won't cause major change in result.

rm(ind_cv)
```

We use the generated folds in above to search the best $\lambda$:
```{r eval = FALSE}

lambda_search <- seq(4, 8, 0.1)

#try all the possible lambdas, and result in a RMSE table

ub_tune <- foreach(l = lambda_search, .combine = "cbind.data.frame") %:% 
  foreach(k = 1:5, .combine = "c", .packages = "data.table") %dopar% {
    u_bias <- train_cv[[k]][
      , .(u_bias = sum(rating - g_mean) / (l + .N)), by = .(userId)]
    
    pred <- u_bias[test_cv[[k]], on = .(userId)][
      , .(err = g_mean + u_bias - rating)]
    
    sqrt(mean(pred$err * pred$err))
  }
```

```{r}
setDT(ub_tune)
setnames(ub_tune, as.character(lambda_search))

#take the mean value over each column 
#to get the final cross validation result for each lambda
ub_rmse <- ub_tune[, lapply(.SD, mean)]

ub_rmse
```

```{r echo = FALSE}
qplot(lambda_search, as.numeric(ub_rmse[1, ]), geom = c("point", "line"), 
      main = "Lambda search visualisation of u_bias")
```

```{r eval = FALSE}
#take the lambda with the best cross validation RMSE
#apply it to the u_bias formula
lambda_u <- lambda_search[which.min(ub_rmse[1,])]

u_bias <- edx[, .(u_bias = sum(rating - g_mean) / (lambda_u + .N)), 
                       by = .(userId)]

rm(ub_rmse, ub_tune, lambda_search, lambda_u)
```

We can use the same method to find the bias of each movie, so that our mean is adjusted not only toward each user real mean, but also toward each movie real mean. So the $\hat{r_{ui}} = g\_mean + u\_bias + m\_bias$, and the $b_m$ is:
$$
b_m = \frac{\sum_{u \in N}{(r_u - \bar{r} - b_u)}}{\lambda + N}
$$
From the above formula we can tell, the movie's real mean varies on each user. It is not like user's mean is relying on each user's own perspective, movie's real mean is a combination of all watchers with different perspectives, so the above formula takes the rater's perspective into account of the calculation. 

```{r eval = FALSE}

lambda_search <- seq(1, 5, 0.1)

#again try all the possible lambdas, and result in a RMSE table

mb_tune <- foreach(l = lambda_search, .combine = "cbind.data.frame") %:% 
  foreach(k = 1:5, .combine = "c", .packages = "data.table") %dopar% {
    m_bias <- u_bias[train_cv[[k]], on = .(userId)][
      , .(m_bias = sum(rating - g_mean - u_bias) / (l + .N)), 
      by = .(movieId)]
    
    pred <- m_bias[u_bias[test_cv[[k]], 
                          on = .(userId)], 
                   on = .(movieId)][
                     , .(err = g_mean + u_bias + m_bias - rating)]
    
    sqrt(mean(pred$err * pred$err))
  }
```

```{r}

setDT(mb_tune)
setnames(mb_tune, as.character(lambda_search))

#take the mean value over each column 
#to get the final cross validation result for each lambda
mb_rmse <- mb_tune[, lapply(.SD, mean)]

mb_rmse
```

```{r echo = FALSE}
qplot(lambda_search, as.numeric(mb_rmse[1,]), geom = c("point", "line"), 
      main = "Lambda search visualisation of m_bias")
```

```{r eval = FALSE}
#take the lambda with the best cross validation RMSE
#apply it to the u_bias formula
lambda_m <- lambda_search[which.min(mb_rmse[1,])]

m_bias <- edx[u_bias, on = .(userId)][
  , .(m_bias = sum(rating - g_mean - u_bias) / (lambda_m + .N)), 
  by = .(movieId)]

rm(mb_tune, mb_rmse, lambda_search, lambda_m, train_cv, test_cv)
```

By now, we have finished the centralisation process under 
$\bar{r_{ui}} = \bar{r_{g}} + b_u + b_m$. We have to stress that this $\bar{r_{ui}}$ varies on different user-movie combinations, so it can be generalised across all the elements of our Rating matrix, regardless the $r_{ui}$ is known to us or not. This generalisation property makes it to be versatile in the predictions. 

###Genres bias
```{r, echo = FALSE}
options(width = 70)

knitr::kable(edx[9,])
```
We use the beginning example to remind ourselves that, the 'genres' information of each movie are given, simultaneously we can an assumption that each user also has some preferences toward some particular genres, we call it user genre bias $g_u$. Instead of being a single numeric value, we assume that $\vec{g_u}$ is a vector, why? That vector assumption is inspired from the movie genres. In above "The Lion King" example, we see the genres are categorised as: 
```{r}
edx[9,]$genres
```
One movie has multiple genres, but we can not quantify which genre is dominant. This multi-genres attribute is also applicable to users, like the same example we just used, we can not tell the user $1$ rated "The Lion King" $5$ star is because she likes the the adventure genre, the animation genre, or the musical genre of the movie, we don't know what her dominant genre taste is. And it is also possible like the movie, she likes all the 5 genres in the movie, but out of those 5 she might have stronger preference on musical genre over the rest. 

Now we have enough reason to not only take the user genre $\vec{g_u}$ as a vector, but also treat the movie genre as a vector $\vec{g_m}$ too. So to combine them together, we assume there is a genre bias $b_g = \vec{g_m} \cdot \vec{g_u}$. Next let's find the $\vec{g_m}$ for each movie, then use those movie $\vec{g_m}$ to find $\vec{g_u}$ for each user, after all we can use them to construct the $b_g$ in regard to different 'userId'-'movieId' pairs in our prediction. 

Since we are given the genres of movie already, so we will start with constructing each movie's genre vector $\vec{g_m}$ first. Let's begin with some data cleaning on the grenes column to remove the "|". 
```{r eval = FALSE}

genres <- str_split(edx$genres, "\\|")

gen_cat <- genres %>% unlist() %>% unique()

n <- length(gen_cat) 

#only one movie(#8606) has no gen info,
#otherwise we have to exclude those from following process
```

## Final result

## Conclusion

## Refnereces

<div id="refs"></div>

## Appendix
